{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53d0f529-0e35-4466-ac86-0fc56a0c6a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# —————————————————————————————————————————————————————————————————————————\n",
    "def compute_halfway_day(month: int, year: int) -> int:\n",
    "    \"\"\"Default midpoint day for months (Feb leap years, 30 vs 31 days).\"\"\"\n",
    "    if month == 2:\n",
    "        return 15 if ((year % 400 == 0) or ((year % 4 == 0) and (year % 100 != 0))) else 14\n",
    "    return 16 if month in {1,3,5,7,8,10,12} else 15\n",
    "\n",
    "def parse_dates(val: str):\n",
    "    \"\"\"\n",
    "    Parse a single date string into (year, month, day, is_synthetic).\n",
    "    - “before”/“after”/“circa” ⇒ is_synthetic=1; shift by ∓1 day for before/after.\n",
    "    - Otherwise, your existing slash/or, month-name, and halfway-day logic.\n",
    "    \"\"\"\n",
    "    if pd.isnull(val) or not str(val).strip():\n",
    "        return (np.nan, np.nan, np.nan, 0)\n",
    "\n",
    "    s0 = str(val).strip().lower()\n",
    "    qualifier = next((q for q in (\"before\",\"after\",\"circa\") if q in s0), None)\n",
    "    synthetic = int(qualifier is not None)\n",
    "    # strip qualifier so it doesn’t confuse parsing\n",
    "    s = re.sub(r'\\b(before|after|circa)\\b', '', s0).strip()\n",
    "\n",
    "    month_names = {\n",
    "        'january':1,'february':2,'march':3,'april':4,\n",
    "        'may':5,'june':6,'july':7,'august':8,\n",
    "        'september':9,'october':10,'november':11,'december':12\n",
    "    }\n",
    "\n",
    "    year = month = day = None\n",
    "\n",
    "    # (A) Slash/or logic\n",
    "    if '/' in s or ' or ' in s:\n",
    "        m = re.fullmatch(r'\\s*(\\d{3,4})\\s*/\\s*(\\d{1,4})\\s*', s)\n",
    "        if m:\n",
    "            a,b = m.groups()\n",
    "            year = int(b) if len(b)>=len(a) else int(a[:len(a)-len(b)] + b)\n",
    "            month, day = 1, 1\n",
    "            synthetic = 1\n",
    "        else:\n",
    "            parts = s.split('/') if '/' in s else s.split(' or ')\n",
    "            y1 = re.search(r'\\d{3,4}', parts[0])\n",
    "            y2 = re.search(r'\\d+',       parts[1]) if len(parts)>1 else None\n",
    "            if not y1:\n",
    "                return (np.nan, np.nan, np.nan, 1)\n",
    "            sec = y2.group(0) if y2 else y1.group(0)\n",
    "            year = (int(sec) if len(sec)>=len(y1.group(0))\n",
    "                    else int(y1.group(0)[:len(y1.group(0))-len(sec)] + sec))\n",
    "            # month?\n",
    "            found = next((n for n in month_names if n in s), None)\n",
    "            if not found:\n",
    "                month, day = 7, 1\n",
    "                synthetic = 1\n",
    "            else:\n",
    "                month = month_names[found]\n",
    "                if re.match(r'\\d', s):\n",
    "                    nums = re.findall(r'\\d+', s)\n",
    "                    if not nums:\n",
    "                        return (np.nan, np.nan, np.nan, 1)\n",
    "                    cand = int(nums[0])\n",
    "                    if cand<=31:\n",
    "                        day = cand\n",
    "                    else:\n",
    "                        day = compute_halfway_day(month, year)\n",
    "                        synthetic = 1\n",
    "                else:\n",
    "                    day = compute_halfway_day(month, year)\n",
    "                    synthetic = 1\n",
    "\n",
    "    # (B) No slash/or\n",
    "    else:\n",
    "        nums = re.findall(r'\\d+', s)\n",
    "        if not nums:\n",
    "            return (np.nan, np.nan, np.nan, 1)\n",
    "        found = next((n for n in month_names if n in s), None)\n",
    "\n",
    "        if found:\n",
    "            month = month_names[found]\n",
    "            if re.match(r'\\d', s) and len(nums)>=2:\n",
    "                day, year = int(nums[0]), int(nums[-1])\n",
    "            else:\n",
    "                year = int(nums[-1])\n",
    "                day = compute_halfway_day(month, year)\n",
    "                synthetic = 1\n",
    "        else:\n",
    "            if len(nums)==1:\n",
    "                year, month, day = int(nums[0]), 7, 1\n",
    "                synthetic = 1\n",
    "            elif re.match(r'\\d', s) and len(nums)>=2:\n",
    "                day, year = int(nums[0]), int(nums[-1])\n",
    "                month = 7\n",
    "            else:\n",
    "                year, month, day = int(nums[-1]), 7, 1\n",
    "                synthetic = 1\n",
    "\n",
    "    # apply before/after shift\n",
    "    try:\n",
    "        dt = datetime(year, month, day)\n",
    "        if qualifier == \"before\":\n",
    "            dt -= timedelta(days=1)\n",
    "        elif qualifier == \"after\":\n",
    "            dt += timedelta(days=1)\n",
    "        year, month, day = dt.year, dt.month, dt.day\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return (year, month, day, synthetic)\n",
    "\n",
    "def create_datetime(row, prefix: str):\n",
    "    \"\"\"\n",
    "    Build a Timestamp or datetime for a row using columns:\n",
    "      {prefix}_year, {prefix}_month, {prefix}_day.\n",
    "    Returns pd.NaT if any component is null or invalid.\n",
    "    \"\"\"\n",
    "    y, m, d = row[f'{prefix}_year'], row[f'{prefix}_month'], row[f'{prefix}_day']\n",
    "    if pd.isnull(y) or pd.isnull(m) or pd.isnull(d):\n",
    "        return pd.NaT\n",
    "    y,m,d = int(y), int(m), int(d)\n",
    "    try:\n",
    "        # native datetime for y<1678, else pandas.Timestamp\n",
    "        return datetime(y,m,d) if y<1678 else pd.Timestamp(year=y,month=m,day=d)\n",
    "    except ValueError:\n",
    "        return pd.NaT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "688bd20a-50e1-4189-ac9c-b2f0bd04443b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 97 rows of missing ids in the raw dataset\n",
      "These are saved to ../data/thepeerage/bad_stuff/missing_person_ID.csv.\n",
      "Dropping them\n",
      "There are 0 rows of missing pages in the raw dataset\n",
      "These are saved to ../data/thepeerage/bad_stuff/missing_person_Page.csv.\n",
      "There are 0 rows of missing ids in the peers dataset\n",
      "There are 0 rows of missing types in the peers dataset\n",
      "There are 0 rows of missing pages in the source dataset\n",
      "There are 0 rows of missing sourceID in the source dataset\n",
      "There are 0 rows of missing Source in the source dataset\n",
      "There are 4 peer IDs not in the raw...\n",
      "These are saved to ../data/thepeerage/bad_stuff/peers_not_in_raw_ID.csv.\n",
      "Dropping them\n",
      "We begin with 757192 rows of the raw df\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ====================== File Paths & Data Loading ======================\n",
    "rawpath = '../data/thepeerage/raw'\n",
    "bad_stuff = '../data/thepeerage/bad_stuff'\n",
    "\n",
    "source = pd.read_csv(os.path.join(rawpath, 'sources.tsv'), sep='\\t')\n",
    "peers = pd.read_csv(os.path.join(rawpath, 'british_peers_and_orders.tsv'), sep='\\t')\n",
    "raw = pd.read_csv(os.path.join(rawpath, 'entire_thepeerage.tsv'), sep='\\t')\n",
    "\n",
    "print(f\"There are {len(raw[raw['ID'].isnull()])} rows of missing ids in the raw dataset\")\n",
    "raw[raw['ID'].isnull()].to_csv(os.path.join(bad_stuff, 'missing_person_ID.csv'))\n",
    "print(f\"These are saved to {os.path.join(bad_stuff, 'missing_person_ID.csv')}.\")\n",
    "raw = raw[raw['ID'].notnull()]\n",
    "print(\"Dropping them\")\n",
    "print(f\"There are {len(raw[raw['Page'].isnull()])} rows of missing pages in the raw dataset\")\n",
    "raw[raw['Page'].isnull()].to_csv(os.path.join(bad_stuff, 'missing_person_Page.csv'))\n",
    "print(f\"These are saved to {os.path.join(bad_stuff, 'missing_person_Page.csv')}.\")\n",
    "print(f\"There are {len(peers[peers['id'].isnull()])} rows of missing ids in the peers dataset\")\n",
    "print(f\"There are {len(peers[peers['type'].isnull()])} rows of missing types in the peers dataset\")\n",
    "print(f\"There are {len(source[source['Page'].isnull()])} rows of missing pages in the source dataset\")\n",
    "print(f\"There are {len(source[source['SourceID'].isnull()])} rows of missing sourceID in the source dataset\")\n",
    "print(f\"There are {len(source[source['Source'].isnull()])} rows of missing Source in the source dataset\")\n",
    "print(f\"There are {len(peers[~peers['id'].isin(raw['ID'])])} peer IDs not in the raw...\")\n",
    "peers[~peers['id'].isin(raw['ID'])].to_csv(os.path.join(bad_stuff, 'peers_not_in_raw_ID.csv'))\n",
    "print(f\"These are saved to {os.path.join(bad_stuff, 'peers_not_in_raw_ID.csv')}.\")\n",
    "peers = peers[peers['id'].isin(raw['ID'])]\n",
    "print(\"Dropping them\")\n",
    "peers = peers.set_index('id')\n",
    "df = raw\n",
    "df = df.set_index('ID')\n",
    "print(f\"We begin with {len(df)} rows of the raw df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0b1b161-4ae1-400f-89e9-31b7eaefc624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now, let's merge on our peerage data.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Now, let's merge on our peerage data.\")\n",
    "peers = peers.rename({'type': 'type_of_peer'}, axis=1)\n",
    "df['is_peer'] = 0\n",
    "df['type_of_peer'] = ''\n",
    "for index, row in peers.iterrows():\n",
    "    key     = 'type_of_peer'\n",
    "    current = df.loc[index, key]\n",
    "    new_val = row['type_of_peer']\n",
    "    if current:\n",
    "        df.loc[index, key] = f\"{current};{new_val}\"\n",
    "    else:\n",
    "        df.loc[index, key] = new_val\n",
    "    # …and likewise for is_* flags…\n",
    "\n",
    "df['is_child_of_peer'] = 0\n",
    "df['is_grandchild_of_peer'] = 0\n",
    "df['Extracted Parental Peerage'] = '' # for harony with our hollingsworth processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af5668d5-ca16-47bc-84cb-237b3e1a9892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# Helper: append a peer‐type into a semicolon‐delimited cell,\n",
    "# avoiding duplicates and empty tokens.\n",
    "# Returns a sorted, semicolon‐delimited string of unique types.\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "def append_peerage(cell: str, new_type: str) -> str:\n",
    "    tokens = [t for t in cell.split(';') if t]\n",
    "    types  = set(tokens)\n",
    "    types.add(new_type)\n",
    "    return ';'.join(sorted(types))\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# 0. Ensure all needed columns exist, and reset peerage columns\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "for flag in ['is_child_of_peer', 'is_grandchild_of_peer']:\n",
    "    if flag not in df.columns:\n",
    "        df[flag] = 0\n",
    "    else:\n",
    "        df[flag] = df[flag].astype(int).clip(0,1)\n",
    "\n",
    "for col in ['Extracted Parental Peerage', 'Extracted Grandparental Peerage']:\n",
    "    df[col] = ''  # reset to empty string\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# 1. Ensure 'child' column is string‐typed (no NaNs)\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "df['child'] = df['child'].fillna('').astype(str)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# 2. Traverse peers → children → grandchildren\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "child_not_found      = set()\n",
    "grandchild_not_found = set()\n",
    "\n",
    "for peer_id in peers.index:\n",
    "    peer_type = df.at[peer_id, 'type_of_peer']\n",
    "    child_list = df.at[peer_id, 'child']\n",
    "    if not child_list:\n",
    "        continue  # no children → skip\n",
    "\n",
    "    # ── Handle direct children ─────────────────────────────────\n",
    "    for child_str in child_list.split(';'):\n",
    "        if not child_str:\n",
    "            continue\n",
    "        cid = int(child_str)\n",
    "        if cid not in df.index:\n",
    "            child_not_found.add(cid)\n",
    "            continue\n",
    "\n",
    "        # Mark as child and append parental peerage\n",
    "        df.at[cid, 'is_child_of_peer'] = 1\n",
    "        existing_pp = df.at[cid, 'Extracted Parental Peerage']\n",
    "        df.at[cid, 'Extracted Parental Peerage'] = append_peerage(existing_pp, peer_type)\n",
    "\n",
    "        # ── Handle grandchildren of this peer ──────────────────\n",
    "        grand_list = df.at[cid, 'child']\n",
    "        if not grand_list:\n",
    "            continue\n",
    "\n",
    "        for grand_str in grand_list.split(';'):\n",
    "            if not grand_str:\n",
    "                continue\n",
    "            gid = int(grand_str)\n",
    "            if gid not in df.index:\n",
    "                grandchild_not_found.add(gid)\n",
    "                continue\n",
    "\n",
    "            # Mark as grandchild and append grandparental peerage\n",
    "            df.at[gid, 'is_grandchild_of_peer'] = 1\n",
    "            existing_gpp = df.at[gid, 'Extracted Grandparental Peerage']\n",
    "            df.at[gid, 'Extracted Grandparental Peerage'] = append_peerage(existing_gpp, peer_type)\n",
    "\n",
    "# At the end:\n",
    "# - df['Extracted Parental Peerage']  contains unique parent‐peer types\n",
    "# - df['Extracted Grandparental Peerage'] contains unique grandparent‐peer types\n",
    "# - child_not_found and grandchild_not_found list any missing IDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a50a4e2-7b1d-4a6a-882a-79a1c36e7aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Extracted Parental Peerage\n",
       "                                                                                                            697578\n",
       "baronet                                                                                                      27060\n",
       "baron                                                                                                         7621\n",
       "baron;baron;baronet;baronet                                                                                   2731\n",
       "baron;earl;earl;viscount;baron;viscount                                                                       2116\n",
       "                                                                                                             ...  \n",
       "baron_by_writ;duke;duke;earl;baron_by_writ;earl                                                                  1\n",
       "baron;baronet;earl;jacobite;marquess;marquess;earl;viscount;baron;baronet;jacobite;jacobite;viscount             1\n",
       "baron;earl;marquess;marquess;earl;baron;baron;baron;viscount                                                     1\n",
       "baron;baronet;duke;earl;marquess;marquess;duke;earl;viscount;baron;baron;baronet;viscount                        1\n",
       "baron;baronet;duke;earl;marquess;marquess;duke;earl;earl;earl;earl;viscount;baron;baron;baronet;viscount         1\n",
       "Name: count, Length: 376, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Extracted Parental Peerage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1ce6d5-6daa-4ab4-978d-0fcef95ed910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74ced7ab-2b11-464b-a5cf-78f66ab9ce9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname_clean</th>\n",
       "      <th>First Forename</th>\n",
       "      <th>Last Surname</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>CHARLES PHILIP ARTHUR GEORGE MOUNTBATTEN WINDSOR</td>\n",
       "      <td>CHARLES</td>\n",
       "      <td>MOUNTBATTEN WINDSOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>OTTON GRAF VON BALLENSTEDT</td>\n",
       "      <td>OTTON</td>\n",
       "      <td>BALLENSTEDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>JOSEPH GRAF VON HOHENZOLLERN SIGMARINGEN</td>\n",
       "      <td>JOSEPH</td>\n",
       "      <td>HOHENZOLLERN SIGMARINGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>KARL FRIEDRICH GRAF VON HOHENZOLLERN SIGMARINGEN</td>\n",
       "      <td>KARL</td>\n",
       "      <td>HOHENZOLLERN SIGMARINGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>EITEL FRIEDRICH IV GRAF VON HOHENZOLLERN HECHI...</td>\n",
       "      <td>EITEL</td>\n",
       "      <td>HOHENZOLLERN HECHINGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759726.0</th>\n",
       "      <td>ANASTATIA BEEVOR</td>\n",
       "      <td>ANASTATIA</td>\n",
       "      <td>BEEVOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759727.0</th>\n",
       "      <td>JOHN BEEVOR</td>\n",
       "      <td>JOHN</td>\n",
       "      <td>BEEVOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759728.0</th>\n",
       "      <td>LAMBERT BLACKWELL FOSTER</td>\n",
       "      <td>LAMBERT</td>\n",
       "      <td>FOSTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759729.0</th>\n",
       "      <td>MARY GREENE BROWNE</td>\n",
       "      <td>MARY</td>\n",
       "      <td>BROWNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759730.0</th>\n",
       "      <td>R E BROWNE</td>\n",
       "      <td>R</td>\n",
       "      <td>BROWNE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>757192 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             fullname_clean First Forename  \\\n",
       "ID                                                                           \n",
       "1.0        CHARLES PHILIP ARTHUR GEORGE MOUNTBATTEN WINDSOR        CHARLES   \n",
       "2.0                              OTTON GRAF VON BALLENSTEDT          OTTON   \n",
       "3.0                JOSEPH GRAF VON HOHENZOLLERN SIGMARINGEN         JOSEPH   \n",
       "4.0        KARL FRIEDRICH GRAF VON HOHENZOLLERN SIGMARINGEN           KARL   \n",
       "5.0       EITEL FRIEDRICH IV GRAF VON HOHENZOLLERN HECHI...          EITEL   \n",
       "...                                                     ...            ...   \n",
       "759726.0                                   ANASTATIA BEEVOR      ANASTATIA   \n",
       "759727.0                                        JOHN BEEVOR           JOHN   \n",
       "759728.0                           LAMBERT BLACKWELL FOSTER        LAMBERT   \n",
       "759729.0                                 MARY GREENE BROWNE           MARY   \n",
       "759730.0                                         R E BROWNE              R   \n",
       "\n",
       "                      Last Surname  \n",
       "ID                                  \n",
       "1.0            MOUNTBATTEN WINDSOR  \n",
       "2.0                    BALLENSTEDT  \n",
       "3.0       HOHENZOLLERN SIGMARINGEN  \n",
       "4.0       HOHENZOLLERN SIGMARINGEN  \n",
       "5.0         HOHENZOLLERN HECHINGEN  \n",
       "...                            ...  \n",
       "759726.0                    BEEVOR  \n",
       "759727.0                    BEEVOR  \n",
       "759728.0                    FOSTER  \n",
       "759729.0                    BROWNE  \n",
       "759730.0                    BROWNE  \n",
       "\n",
       "[757192 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "\n",
    "# Expanded list of honourifics/ranks...\n",
    "honorifics = [\n",
    "    # Civilian titles\n",
    "    'Mr', 'Mrs', 'Ms', 'Miss', 'Mx',\n",
    "    'Dr', 'Prof', 'Professor',\n",
    "    'Sir', 'Dame', 'Lord', 'Lady',\n",
    "    'Rev', 'Reverend', 'Father', 'Fr', 'Pastor',\n",
    "    'Rabbi', 'Imam',\n",
    "    'Hon', 'Honorable', 'Right Honourable', 'Rt Hon',\n",
    "    # Army ranks\n",
    "    'Private', 'Pvt',\n",
    "    'Corporal', 'Cpl',\n",
    "    'Sergeant', 'Sgt',\n",
    "    'Lieutenant', 'Lt', \n",
    "    'Captain', 'Capt',\n",
    "    'Major', 'Maj',\n",
    "    'Lieutenant Colonel', 'Lt Col', 'Lt-Col',\n",
    "    'Colonel', 'Col',\n",
    "    'Brigadier', 'Brigadier General', 'Brigadier-General',\n",
    "    'Major General', 'Maj Gen', 'Maj-Gen',\n",
    "    'Lieutenant General', 'Lt Gen', 'Lt-Gen',\n",
    "    'General', 'Gen',\n",
    "    'Field Marshal',\n",
    "    # Naval ranks\n",
    "    'Seaman', 'Able Seaman', 'AB',\n",
    "    'Petty Officer', 'Chief Petty Officer',\n",
    "    'Midshipman',\n",
    "    'Lieutenant Commander',\n",
    "    'Commander',\n",
    "    'Captain RN',\n",
    "    'Commodore',\n",
    "    'Rear Admiral',\n",
    "    'Vice Admiral',\n",
    "    'Admiral',\n",
    "    # Air-Force ranks\n",
    "    'Pilot Officer',\n",
    "    'Flying Officer',\n",
    "    'Flight Lieutenant',\n",
    "    'Squadron Leader',\n",
    "    'Wing Commander',\n",
    "    'Group Captain',\n",
    "    'Air Commodore',\n",
    "    'Air Vice Marshal', 'Air Vice-Marshal',\n",
    "    'Air Marshal',\n",
    "    'Air Chief Marshal',\n",
    "    'Marshal of the RAF',\n",
    "    # Religious / other\n",
    "    'Saint', 'St'\n",
    "]\n",
    "\n",
    "def escape_with_optional_dot(title: str) -> str:\n",
    "    parts = title.split()\n",
    "    return r'\\s+'.join(re.escape(p) + r'\\.?' for p in parts)\n",
    "\n",
    "# Compile honourific‐stripping pattern\n",
    "escaped_fragments = (escape_with_optional_dot(h) for h in honorifics)\n",
    "hon_pattern = re.compile(\n",
    "    r'^(?:' + r'|'.join(escaped_fragments) + r')\\b\\s*',\n",
    "    flags=re.IGNORECASE\n",
    ")\n",
    "\n",
    "def strip_honorifics(name: str) -> str:\n",
    "    \"\"\"\n",
    "    1. Drop any 'formerly ...' suffix.\n",
    "    2. Remove leading honourific/rank.\n",
    "    \"\"\"\n",
    "    if pd.isna(name):\n",
    "        return name\n",
    "    # 1) Keep only text before 'formerly'\n",
    "    name = re.split(r'\\bformerly\\b', name, flags=re.IGNORECASE)[0].strip()\n",
    "    # 2) Strip leading honorific\n",
    "    return hon_pattern.sub('', name).strip()\n",
    "\n",
    "def clean_string(s: str) -> str:\n",
    "    \"\"\"\n",
    "    1. Remove parenthesized content.\n",
    "    2. Normalize to NFKD and drop diacritics.\n",
    "    3. Replace dashes with space.\n",
    "    4. Keep only ASCII letters and spaces.\n",
    "    5. Collapse multiple spaces and trim.\n",
    "    \"\"\"\n",
    "    if pd.isna(s):\n",
    "        return s\n",
    "    s = re.sub(r'\\(.*?\\)', '', s)\n",
    "    s = unicodedata.normalize('NFKD', s)\n",
    "    s = re.sub(r'[-–—]+', ' ', s)\n",
    "    s = re.sub(r'[^A-Za-z ]+', '', s)\n",
    "    return re.sub(r'\\s{2,}', ' ', s).strip()\n",
    "\n",
    "# Apply to DataFrame\n",
    "df['fullname_clean'] = df['fullname'].apply(strip_honorifics).str.upper()\n",
    "df['First Forename'] = df['fullname_clean'].str.split().str[0]\n",
    "df['Last Surname']   = df['fullname_clean'].str.split().str[-1]\n",
    "\n",
    "for col in ['fullname_clean', 'First Forename', 'Last Surname']:\n",
    "    df[col] = df[col].apply(clean_string)\n",
    "\n",
    "# View the cleaned columns\n",
    "df[['fullname_clean', 'First Forename', 'Last Surname']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd1449e0-482d-43f7-864a-f2b7b297ec18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 0 children not found\n",
      "We have 0 grandchildren not found\n",
      "Child not found list saved to: ../data/thepeerage/bad_stuff/child_not_found.csv\n",
      "Grandchild not found list saved to: ../data/thepeerage/bad_stuff/grandchild_not_found.csv\n"
     ]
    }
   ],
   "source": [
    "            \n",
    "print(f\"We have {len(child_not_found)} children not found\")\n",
    "print(f\"We have {len(grandchild_not_found)} grandchildren not found\")\n",
    "\n",
    "# Save these two sets to CSV files.\n",
    "child_not_found_df = pd.DataFrame({'child_not_found': list(child_not_found)})\n",
    "child_not_found_file = os.path.join(bad_stuff, 'child_not_found.csv')\n",
    "child_not_found_df.to_csv(child_not_found_file, index=False)\n",
    "print(f\"Child not found list saved to: {child_not_found_file}\")\n",
    "\n",
    "grandchild_not_found_df = pd.DataFrame({'grandchild_not_found': list(grandchild_not_found)})\n",
    "grandchild_not_found_file = os.path.join(bad_stuff, 'grandchild_not_found.csv')\n",
    "grandchild_not_found_df.to_csv(grandchild_not_found_file, index=False)\n",
    "print(f\"Grandchild not found list saved to: {grandchild_not_found_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f29a76f5-91bc-4176-b62a-37ebe9f1eca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) PARSE both born & died into (year,month,day,is_synthetic)\n",
    "df[['born_year','born_month','born_day','is_synthetic_birthdate']] = (\n",
    "    df['born']\n",
    "      .apply(lambda x: pd.Series(parse_dates(x)))\n",
    ")\n",
    "\n",
    "df[['died_year','died_month','died_day','is_synthetic_deathdate']] = (\n",
    "    df['died']\n",
    "      .apply(lambda x: pd.Series(parse_dates(x)))\n",
    ")\n",
    "\n",
    "# 2) BUILD actual datetime columns, using the same prefixes:\n",
    "df['born_datetime'] = df.apply(\n",
    "    lambda row: create_datetime(row, prefix='born'),\n",
    "    axis=1\n",
    ")\n",
    "df['died_datetime'] = df.apply(\n",
    "    lambda row: create_datetime(row, prefix='died'),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# 3) (Optional) A human-readable string form:\n",
    "df['born_datetime_str'] = df['born_datetime'].apply(\n",
    "    lambda x: x.strftime('%d-%m-%Y') if pd.notnull(x) else np.nan\n",
    ")\n",
    "\n",
    "df['died_datetime_str'] = df['died_datetime'].apply(\n",
    "    lambda x: x.strftime('%d-%m-%Y') if pd.notnull(x) else np.nan\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "614520d6-5bbb-4586-bdcc-84ddfeb30aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets now make it as equivilent as possible to hollingsworth:\n",
    "df = df.rename({'fullname_clean': 'Full_Name_l'}, axis=1)\n",
    "df = df.rename({'First Forename': 'First Forename_l'}, axis=1)\n",
    "df = df.rename({'Last Surname': 'Last Surname_l'}, axis=1)\n",
    "df = df.rename({'gender': 'Gender_l'}, axis=1)\n",
    "df = df.rename({'born_day': 'born_day_l'}, axis=1)\n",
    "df = df.rename({'born_month': 'born_month_l'}, axis=1)\n",
    "df = df.rename({'born_year': 'born_year_l'}, axis=1)\n",
    "df = df.rename({'is_synthetic_birthdate': 'born_accuracy_l'}, axis=1)\n",
    "df = df.rename({'died_day': 'died_day_l'}, axis=1)\n",
    "df = df.rename({'died_month': 'died_month_l'}, axis=1)\n",
    "df = df.rename({'died_year': 'died_year_l'}, axis=1)\n",
    "df = df.rename({'is_synthetic_deathdate': 'died_accuracy_l'}, axis=1)\n",
    "df = df.rename({'born_datetime': 'born_datetime_l'}, axis=1)\n",
    "df = df.rename({'died_datetime': 'died_datetime_l'}, axis=1)\n",
    "df = df.rename({'Extracted Parental Peerage': 'Extracted Parental Peerage_l'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4953df5c-e171-4165-9238-ce6ef243f339",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Full_Name_l',\n",
    "         'First Forename_l',\n",
    "         'Last Surname_l',\n",
    "         'Gender_l',\n",
    "         'born_day_l',\n",
    "         'born_month_l',\n",
    "         'born_year_l',\n",
    "         'born_accuracy_l',\n",
    "         'died_day_l',\n",
    "         'died_month_l',\n",
    "         'died_year_l',\n",
    "         'died_accuracy_l',\n",
    "         'born_datetime_l',\n",
    "         'died_datetime_l',\n",
    "         'Extracted Parental Peerage_l']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71d3f6ed-8a64-4fa6-8d3a-16af168bfe70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We end with 757192 rows of the df\n",
      "Saving out to ../data/thepeerage/wrangled/wrangled_peerage.csv\n"
     ]
    }
   ],
   "source": [
    "print(f\"We end with {len(df)} rows of the df\")\n",
    "print(f\"Saving out to ../data/thepeerage/wrangled/wrangled_peerage.csv\")\n",
    "df.to_csv('../data/thepeerage/wrangled/wrangled_peerage.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
